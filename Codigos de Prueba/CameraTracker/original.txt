//EDGE IMPULSE
#include <lapor-project-1_inferencing.h>
#include "edge-impulse-sdk/dsp/image/image.hpp"

//WEB SERVER
#include "esp_camera.h"
#include <WiFi.h>
#include "esp_timer.h"
#include "img_converters.h"
#include "Arduino.h"
#include "fb_gfx.h"
#include "soc/soc.h" //disable brownout problems
#include "soc/rtc_cntl_reg.h"  //disable brownout problems
#include "esp_http_server.h"

// Credenciales Wi-Fi
const char *ssid = "WI-FI 623 2.4G"; //"alumnosInfo";
const char *password = "catalinaalmendra"; //"InformaticaUNLP";

#define PART_BOUNDARY "123456789000000000000987654321"

// This project was tested with the AI Thinker Model
#define CAMERA_MODEL_AI_THINKER

#define PWDN_GPIO_NUM     32
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM      0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM        5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

static const char* _STREAM_CONTENT_TYPE = "multipart/x-mixed-replace;boundary=" PART_BOUNDARY;
static const char* _STREAM_BOUNDARY = "\r\n--" PART_BOUNDARY "\r\n";
static const char* _STREAM_PART = "Content-Type: image/jpeg\r\nContent-Length: %u\r\n\r\n";

// Servos
#include <ESP32Servo.h>
#define s1_Pin 12 // Pin del servo X
#define s2_Pin 13 // Pin del servo Y

// EDGE IMPULSE
/* Constant defines -------------------------------------------------------- */
#define EI_CAMERA_RAW_FRAME_BUFFER_COLS           320
#define EI_CAMERA_RAW_FRAME_BUFFER_ROWS           240
#define EI_CAMERA_FRAME_BYTE_SIZE                 3

/* Private variables ------------------------------------------------------- */
static bool debug_nn = false;
static bool is_initialised = false;
uint8_t *snapshot_buf; //points to the output of the capture

/* Function definitions ------------------------------------------------------- */
bool ei_camera_init(void);
void ei_camera_deinit(void);
bool ei_camera_capture(uint32_t img_width, uint32_t img_height, uint8_t *out_buf);
/* Web server functions prototypes -------------------------------------------- */
void startCameraServer(void);
static esp_err_t index_handler(httpd_req_t *req);
static esp_err_t stream_handler(httpd_req_t *req);

//WEB SERVER
httpd_handle_t stream_httpd = NULL;
camera_fb_t * fb = NULL;

// Servos
int X; //Posicion en X ddel objeto en la imagen
int Y; //Posicion en X ddel objeto en la imagen
int MAX_X = 80; //Posicion maxima en X
int MAX_Y = 80; //Posicion maxima en Y
int DIST_X; //Distancia X del objeto al centro de la imagen
int DIST_Y; //Distancia Y del objeto al centro de la imagen
int FOV_X = 40; //Angulo FOV en X (Grados)
int FOV_Y = 60; //Angulo FOV en Y (Grados)
int ANG_X; //Angulo de corrimiento del objeto al centro de la imagen
int ANG_Y; //Angulo de corrimiento del objeto al centro de la imagen
int lastPosS1;
int lastPosS2;
int positionS1; //Posicion del Servo 1
int positionS2; //Posicion del Servo 2
Servo s1;
Servo s2;

// Add these for task handling
TaskHandle_t inferenceTask;
TaskHandle_t streamTask;

// Function declarations for tasks
void inferenceLoop(void * parameter);
void streamLoop(void * parameter);

// Add this global variable at the top with other globals
bool serverStarted = false;

/**
* @brief      Arduino setup function
*/
void setup() {
  WRITE_PERI_REG(RTC_CNTL_BROWN_OUT_REG, 0); //disable brownout detector
 
  Serial.begin(115200);
  Serial.setDebugOutput(false);

  // Initialize EI camera
  if (ei_camera_init() == false) {
        ei_printf("Failed to initialize Camera!\r\n");
    }
    else {
        ei_printf("Camera initialized\r\n");
    }
  
  // Wi-Fi connection
  WiFi.begin(ssid, password);

  while (WiFi.status() != WL_CONNECTED) {
    delay(500);
    Serial.print(".");
  }

  Serial.println("");
  Serial.println("WiFi connected");
  
  Serial.print("Camera Stream Ready! Go to: http://");
  Serial.print(WiFi.localIP());
  
  // Start streaming web server
  startCameraServer();
  ei_printf("\r\nStarting continious inference in 2 seconds...\n");
  ei_sleep(2000);

  // Create tasks for different cores
  xTaskCreatePinnedToCore(
      inferenceLoop,    // Task function
      "InferenceTask",  // Name
      10000,           // Stack size
      NULL,            // Parameters
      1,              // Priority
      &inferenceTask, // Task handle
      0              // Core ID (0)
  );

  xTaskCreatePinnedToCore(
      streamLoop,     // Task function
      "StreamTask",   // Name
      10000,         // Stack size
      NULL,          // Parameters
      1,             // Priority
      &streamTask,   // Task handle
      1             // Core ID (1)
  );

  // Initialize servos
  s1.attach(s1_Pin);
  s2.attach(s2_Pin);
}

/**
* @brief      Get data and run inferencing
*
* @param[in]  debug  Get debug info if true
*/
void loop() {
    // Empty - tasks handle the work
    vTaskDelay(1000);
}

// New task function for inference
void inferenceLoop(void * parameter) {
    Serial.print("Inference task running on core: ");
    Serial.println(xPortGetCoreID());
    
    while(true) {
        // Move the inference code from the original loop() here
        // Get new image from camera
        fb = esp_camera_fb_get();
        
        // instead of wait_ms, we'll wait on the signal, this allows threads to cancel us...
        if (ei_sleep(5) != EI_IMPULSE_OK) {
            return;
        }

        snapshot_buf = (uint8_t*)malloc(EI_CAMERA_RAW_FRAME_BUFFER_COLS * EI_CAMERA_RAW_FRAME_BUFFER_ROWS * EI_CAMERA_FRAME_BYTE_SIZE);

        // Check if allocation was successful
        if(snapshot_buf == nullptr) {
            ei_printf("ERR: Failed to allocate snapshot buffer!\n");
            return;
        }

        ei::signal_t signal;
        signal.total_length = EI_CLASSIFIER_INPUT_WIDTH * EI_CLASSIFIER_INPUT_HEIGHT;
        signal.get_data = &ei_camera_get_data;

        if (ei_camera_capture((size_t)EI_CLASSIFIER_INPUT_WIDTH, (size_t)EI_CLASSIFIER_INPUT_HEIGHT, snapshot_buf) == false) {
            ei_printf("Failed to capture image\r\n");
            //free(snapshot_buf);
            //return;
        }

        ei_impulse_result_t result = { 0 };

        EI_IMPULSE_ERROR err = run_classifier(&signal, &result, debug_nn);
        if (err != EI_IMPULSE_OK) {
            ei_printf("ERR: Failed to run classifier (%d)\n", err);
            return;
        }
      
        //ei_printf("Object detection bounding boxes:\r\n");
        for (uint32_t i = 0; i < result.bounding_boxes_count; i++) {
            ei_impulse_result_bounding_box_t bb = result.bounding_boxes[i];
            if (bb.value == 0) {
                continue;
            }

            ei_printf("  %s (%f) [ x: %u, y: %u, width: %u, height: %u ]\r\n",
                    bb.label,
                    bb.value,
                    bb.x,
                    bb.y,
                    bb.width,
                    bb.height);
          
          X = (int) bb.x + bb.width*0.5;
          Y = (int) bb.y + bb.height*0.5;
        }

        DIST_X = (1)*(X - (MAX_X*0.5));
        DIST_Y = (1)*(Y - (MAX_X*0.5));
        ANG_X = DIST_X * FOV_X / MAX_X;
        ANG_Y = DIST_Y * FOV_Y / MAX_Y;

        //lastPosS1 = positionS1;
        //lastPosS2 = positionS1;

        positionS1 = ANG_X + 90;
        positionS2 = ANG_Y + 90;

        //Serial.print("angX: ");
        //Serial.print(ANG_X);
        //Serial.print(",angY: ");
        //Serial.println(ANG_Y);

        s1.write(positionS1);
        s2.write(positionS2);
        //s1.write((positionS1+lastPosS1)/2);
        //s2.write((positionS2+lastPosS2)/2);

        free(snapshot_buf);
        delay(500);
        esp_camera_fb_return(fb);
    }
}

// New task function for streaming
void streamLoop(void * parameter) {
    Serial.print("Stream task running on core: ");
    Serial.println(xPortGetCoreID());
    
    while(true) {
        if(!serverStarted) {
            Serial.println("Starting camera server...");
            startCameraServer();
            if(stream_httpd != NULL) {
                serverStarted = true;
                Serial.println("Camera server started successfully");
            } else {
                Serial.println("Failed to start camera server");
                vTaskDelay(5000); // Wait 5 seconds before trying again
            }
        }
        vTaskDelay(1000); // Longer delay since we only need to check occasionally
    }
}

//EDGE IMPULSE
/**
 * @brief   Setup image sensor & start streaming
 *
 * @retval  false if initialisation failed
 */
bool ei_camera_init(void) {

  if (is_initialised) 
      return true;

  camera_config_t config;
    config.ledc_channel = LEDC_CHANNEL_0;
    config.ledc_timer = LEDC_TIMER_0;
    config.pin_d0 = Y2_GPIO_NUM;
    config.pin_d1 = Y3_GPIO_NUM;
    config.pin_d2 = Y4_GPIO_NUM;
    config.pin_d3 = Y5_GPIO_NUM;
    config.pin_d4 = Y6_GPIO_NUM;
    config.pin_d5 = Y7_GPIO_NUM;
    config.pin_d6 = Y8_GPIO_NUM;
    config.pin_d7 = Y9_GPIO_NUM;
    config.pin_xclk = XCLK_GPIO_NUM;
    config.pin_pclk = PCLK_GPIO_NUM;
    config.pin_vsync = VSYNC_GPIO_NUM;
    config.pin_href = HREF_GPIO_NUM;
    config.pin_sscb_sda = SIOD_GPIO_NUM;
    config.pin_sscb_scl = SIOC_GPIO_NUM;
    config.pin_pwdn = PWDN_GPIO_NUM;
    config.pin_reset = RESET_GPIO_NUM;
    config.xclk_freq_hz = 20000000;
    config.pixel_format = PIXFORMAT_JPEG; 
    config.fb_location = CAMERA_FB_IN_PSRAM;
    config.grab_mode = CAMERA_GRAB_WHEN_EMPTY;
    config.ledc_timer = LEDC_TIMER_0;
    config.ledc_channel = LEDC_CHANNEL_0;
  
  if(psramFound()){
    config.frame_size = FRAMESIZE_QVGA;//FRAMESIZE_UXGA;
    config.jpeg_quality = 12;
    config.fb_count = 2;
    Serial.printf("PSRAM FOUND\n");
  } else {
    config.frame_size = FRAMESIZE_SVGA;
    config.jpeg_quality = 12;
    config.fb_count = 1;
  }

    //initialize the camera
    esp_err_t err = esp_camera_init(&config);
    if (err != ESP_OK) {
      Serial.printf("Camera init failed with error 0x%x\n", err);
      return false;
    }

    sensor_t * s = esp_camera_sensor_get();
    // initial sensors are flipped vertically and colors are a bit saturated
    if (s->id.PID == OV3660_PID) {
      s->set_vflip(s, 1); // flip it back
      s->set_brightness(s, 1); // up the brightness just a bit
      s->set_saturation(s, 0); // lower the saturation
    }

    is_initialised = true;
    return true;
}

/**
 * @brief Stop streaming of sensor data
 */
void ei_camera_deinit(void) {

    //deinitialize the camera
    esp_err_t err = esp_camera_deinit();

    if (err != ESP_OK)
    {
        ei_printf("Camera deinit failed\n");
        return;
    }

    is_initialised = false;
    return;
}


/**
 * @brief      Capture, rescale and crop image
 *
 * @param[in]  img_width     width of output image
 * @param[in]  img_height    height of output image
 * @param[in]  out_buf       pointer to store output image, NULL may be used
 *                           if ei_camera_frame_buffer is to be used for capture and resize/cropping.
 *
 * @retval     false if not initialised, image captured, rescaled or cropped failed
 *
 */
bool ei_camera_capture(uint32_t img_width, uint32_t img_height, uint8_t *out_buf) {
    bool do_resize = false;

    if (!is_initialised) {
        ei_printf("ERR: Camera is not initialized\r\n");
        return false;
    }

    if (!fb) {
        ei_printf("Camera capture failed\n");
        return false;
    }

   bool converted = fmt2rgb888(fb->buf, fb->len, PIXFORMAT_JPEG, snapshot_buf);

   if(!converted){
       ei_printf("Conversion failed\n");
       return false;
   }

    if ((img_width != EI_CAMERA_RAW_FRAME_BUFFER_COLS)
        || (img_height != EI_CAMERA_RAW_FRAME_BUFFER_ROWS)) {
        do_resize = true;
    }

    if (do_resize) {
        ei::image::processing::crop_and_interpolate_rgb888(
        out_buf,
        EI_CAMERA_RAW_FRAME_BUFFER_COLS,
        EI_CAMERA_RAW_FRAME_BUFFER_ROWS,
        out_buf,
        img_width,
        img_height);
    }


    return true;
}

static int ei_camera_get_data(size_t offset, size_t length, float *out_ptr)
{
    // we already have a RGB888 buffer, so recalculate offset into pixel index
    size_t pixel_ix = offset * 3;
    size_t pixels_left = length;
    size_t out_ptr_ix = 0;

    while (pixels_left != 0) {
        // Swap BGR to RGB here
        // due to https://github.com/espressif/esp32-camera/issues/379
        out_ptr[out_ptr_ix] = (snapshot_buf[pixel_ix + 2] << 16) + (snapshot_buf[pixel_ix + 1] << 8) + snapshot_buf[pixel_ix];

        // go to the next pixel
        out_ptr_ix++;
        pixel_ix+=3;
        pixels_left--;
    }

    return 0;
}

/**
 * @brief Initializes and starts the camera server for streaming
 *
 * This function sets up an HTTP server to handle camera streaming requests.
 * It configures the server, defines URI handlers for the index page and
 * the video stream, and starts the server if initialization is successful.
 *
 * @return This function does not return a value.
 */
void startCameraServer() {
    if(stream_httpd != NULL) {
        Serial.println("Server is already running");
        return;
    }

    httpd_config_t config = HTTPD_DEFAULT_CONFIG();
    config.server_port = 80;
    config.ctrl_port = 32768;  // Add this line
    config.max_resp_headers = 16;  // Add this line
    
    Serial.println("Starting web server on port: 80");

    httpd_uri_t index_uri = {
        .uri       = "/",
        .method    = HTTP_GET,
        .handler   = index_handler,
        .user_ctx  = NULL
    };

    httpd_uri_t stream_uri = {
        .uri       = "/stream",
        .method    = HTTP_GET,
        .handler   = stream_handler,
        .user_ctx  = NULL
    };

    if (httpd_start(&stream_httpd, &config) == ESP_OK) {
        httpd_register_uri_handler(stream_httpd, &index_uri);
        httpd_register_uri_handler(stream_httpd, &stream_uri);
        Serial.println("HTTP server started");
    } else {
        Serial.println("Error starting HTTP server");
        stream_httpd = NULL;
    }
}

static esp_err_t index_handler(httpd_req_t *req) {
    const char* html = "<!DOCTYPE html>"
        "<html><head>"
        "<meta name='viewport' content='width=device-width, initial-scale=1'>"
        "<title>Camera Tracker</title>"
        "<style>"
        "body { font-family: Georgia, serif; margin: 0; padding: 20px; text-align: center; }"
        "h1 { color: #333; }"
        "img { max-width: 100%; height: auto; margin: 20px 0; }"
        ".controls { margin: 20px 0; }"
        "button { "
        "   background-color: #4CAF50; color: white; border: none; "
        "   padding: 10px 20px; margin: 5px; cursor: pointer; "
        "   border-radius: 4px; font-family: Georgia, serif; "
        "}"
        "button:hover { background-color: #45a049; }"
        "#stream { display: none; }"
        "</style>"
        "</head><body>"
        "<h1>Camera Tracker</h1>"
        "<div class='controls'>"
        "<button onclick='toggleStream()'>Start/Stop Stream</button>"
        "</div>"
        "<img id='stream' src='/stream' alt='Camera Stream'>"
        "<script>"
        "function toggleStream() {"
        "   const stream = document.getElementById('stream');"
        "   if (stream.style.display === 'none') {"
        "       stream.style.display = 'block';"
        "   } else {"
        "       stream.style.display = 'none';"
        "       stream.src = '';"
        "       setTimeout(() => { stream.src = '/stream'; }, 100);"
        "   }"
        "}"
        "</script>"
        "</body></html>";

    httpd_resp_send(req, html, strlen(html));
    return ESP_OK;
}

static esp_err_t stream_handler(httpd_req_t *req) {
    camera_fb_t * fb = NULL;
    esp_err_t res = ESP_OK;
    size_t _jpg_buf_len = 0;
    uint8_t * _jpg_buf = NULL;
    char * part_buf[64];

    res = httpd_resp_set_type(req, _STREAM_CONTENT_TYPE);
    if(res != ESP_OK) {
        return res;
    }

    while(true) {
        fb = esp_camera_fb_get();
        if (!fb) {
            Serial.println("Camera capture failed");
            res = ESP_FAIL;
            break;
        }

        _jpg_buf_len = fb->len;
        _jpg_buf = fb->buf;

        if(res == ESP_OK) {
            size_t hlen = snprintf((char *)part_buf, 64, _STREAM_PART, _jpg_buf_len);
            res = httpd_resp_send_chunk(req, (const char *)part_buf, hlen);
        }
        if(res == ESP_OK) {
            res = httpd_resp_send_chunk(req, (const char *)_jpg_buf, _jpg_buf_len);
        }
        if(res == ESP_OK) {
            res = httpd_resp_send_chunk(req, _STREAM_BOUNDARY, strlen(_STREAM_BOUNDARY));
        }

        esp_camera_fb_return(fb);
        
        if(res != ESP_OK) {
            break;
        }
    }

    return res;
}
